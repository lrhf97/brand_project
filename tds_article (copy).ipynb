{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import csv\n",
    "# For parsing the dates received from twitter in readable formats\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "#To add wait time between requests\n",
    "import time\n",
    "\n",
    "# name the file we want\n",
    "env_file_name = 'lrhf97_twit_cred.env'\n",
    "\n",
    "# designate the path of the file\n",
    "curr_file = pathlib.Path.cwd()\n",
    "\n",
    "# join them\n",
    "env_path = curr_file.joinpath(env_file_name)\n",
    "\n",
    "# load the file\n",
    "load_dotenv(env_path)\n",
    "\n",
    "bearer_token = os.getenv(\"BEARER_TOKEN\")\n",
    "\n",
    "\n",
    "def create_url(max_results=50):\n",
    "    user_id = 3413455348\n",
    "    search_url = \"https://api.twitter.com/2/users/{}/followers?max_results={}\".format(user_id,max_results)\n",
    "\n",
    "    params ={'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n",
    "                    'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
    "                    'next_token': {}}\n",
    "    return (search_url, params)\n",
    "\n",
    "\n",
    "def bearer_oauth(r):\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2FollowersLookupPython\"\n",
    "    return r\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, params, next_token=None):\n",
    "    params['pagination_token'] = next_token # param object recieved form the create_url function\n",
    "    response = requests.request(\"GET\", url, auth=bearer_oauth, params=params)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Request returned an error: {} {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    return response.json()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url = create_url()\n",
    "json_response = connect_to_endpoint(url[0], url[1], next_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'325J0D2OB1OHCZZZ'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response['meta']['next_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(json_response['data'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csvFile = open(\"data3.csv\", \"a\", newline=\"\", encoding='utf-8')\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Create headers for the data you want to save, in this example, we only want save these columns in our dataset\n",
    "csvWriter.writerow(['id', 'created_at', 'location', 'description','username','name','verified', 'followers_count', 'following_count', 'tweet_count','listed_count'])\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_csv(json_response, fileName):\n",
    "\n",
    "    #A counter variable\n",
    "    counter = 0\n",
    "\n",
    "    #Open OR create the target CSV file\n",
    "    csvFile = open(fileName, \"a\", newline=\"\", encoding='utf-8')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "\n",
    "    #Loop through each tweet\n",
    "    for tweet in json_response['data']:\n",
    "        \n",
    "        # We will create a variable for each since some of the keys might not exist for some tweets\n",
    "        # So we will account for that\n",
    "\n",
    "        # 1. ID\n",
    "        id = tweet['id']\n",
    "\n",
    "        # 2. Time created\n",
    "        created_at = dateutil.parser.parse(tweet['created_at'])\n",
    "\n",
    "        # 3. location\n",
    "        if ('location' in tweet):   \n",
    "            location = tweet['location']\n",
    "        else:\n",
    "            location = \" \"\n",
    "\n",
    "        # 4. description\n",
    "        description = tweet['description']\n",
    "\n",
    "        # # 5. names\n",
    "        username = tweet['username']\n",
    "        name = tweet['name']\n",
    "        verified = tweet['verified']\n",
    "\n",
    "        # 6. Tweet metrics\n",
    "        followers_count = tweet['public_metrics']['followers_count']\n",
    "        following_count = tweet['public_metrics']['following_count']\n",
    "        tweet_count = tweet['public_metrics']['tweet_count']\n",
    "        listed_count = tweet['public_metrics']['listed_count']\n",
    "\n",
    "        # Assemble all data in a list\n",
    "        res = [id, created_at, location, description,username,name,verified, followers_count, following_count, tweet_count,listed_count]\n",
    "        \n",
    "        # Append the result to the CSV file\n",
    "        csvWriter.writerow(res)\n",
    "        counter += 1\n",
    "\n",
    "    # When done, close the CSV file\n",
    "    csvFile.close()\n",
    "\n",
    "    # Print the number of tweets for this iteration\n",
    "    print(\"# of Followers added from this response: \", counter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Followers added from this response:  50\n"
     ]
    }
   ],
   "source": [
    "append_to_csv(json_response,'data3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n",
       " 'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
       " 'next_token': {},\n",
       " 'pagination_token': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = url[1]\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is for looping over tweets - going to try to convert it to get the total list of followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Token:  None\n",
      "200\n",
      "Next Token:  325J0D2OB1OHCZZZ\n",
      "# of Followers added from this response:  50\n",
      "Total # of followers added:  50\n",
      "count 50\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  325J0D2OB1OHCZZZ\n",
      "200\n",
      "Next Token:  A4N67M1A2CEHCZZZ\n",
      "# of Followers added from this response:  50\n",
      "Total # of followers added:  100\n",
      "count 100\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  A4N67M1A2CEHCZZZ\n",
      "200\n",
      "Next Token:  TKB9MH0Q4QCHAZZZ\n",
      "# of Followers added from this response:  50\n",
      "Total # of followers added:  150\n",
      "count 150\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  TKB9MH0Q4QCHAZZZ\n",
      "200\n",
      "Next Token:  BM73NRF44PDHAZZZ\n",
      "# of Followers added from this response:  50\n",
      "Total # of followers added:  200\n",
      "count 200\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  BM73NRF44PDHAZZZ\n",
      "200\n",
      "Next Token:  KUQCCEPOJ4QHAZZZ\n",
      "# of Followers added from this response:  50\n",
      "Total # of followers added:  250\n",
      "count 250\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  KUQCCEPOJ4QHAZZZ\n",
      "200\n",
      "Next Token:  D1TR40O7MC71AZZZ\n",
      "# of Followers added from this response:  50\n",
      "Total # of followers added:  300\n",
      "count 300\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  D1TR40O7MC71AZZZ\n",
      "200\n",
      "-------------------\n",
      "# of Followers added from this response:  21\n",
      "Total # of followers added:  321\n",
      "count 321\n",
      "-------------------\n",
      "Total number of results:  321\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Total number of followers we collected from the loop\n",
    "total_followers = 0\n",
    "csv_to_file = \"rsf_list.csv\"\n",
    "# Create file\n",
    "csvFile = open(csv_to_file, \"a\", newline=\"\", encoding='utf-8')\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Create headers for the data you want to save, in this example, we only want save these columns in our dataset\n",
    "csvWriter.writerow(['id', 'created_at', 'location', 'description','username','name','verified', 'followers_count', 'following_count', 'tweet_count','listed_count'])\n",
    "csvFile.close()\n",
    "#next_token=None\n",
    "\n",
    "# for i in range(0,int(max_results/max_users)+1):\n",
    "\n",
    "# Inputs\n",
    "count = 0 # Counting followers per time period\n",
    "max_count = 350 # Max followers\n",
    "max_results = 50\n",
    "flag = True\n",
    "next_token= None\n",
    "\n",
    "# Check if flag is true\n",
    "while flag:\n",
    "    # Check if max_count reached\n",
    "    if count >= max_count:\n",
    "        break\n",
    "    print(\"-------------------\")\n",
    "    print(\"Token: \",next_token)\n",
    "    params['next_token']=next_token\n",
    "    url = create_url(max_results = max_results)        \n",
    "    json_response = connect_to_endpoint(url[0], url[1],params['next_token'])\n",
    "    result_count = json_response['meta']['result_count']\n",
    "\n",
    "    if 'next_token' in json_response['meta']:\n",
    "        # Save the token to use for next call\n",
    "        next_token = json_response['meta']['next_token']\n",
    "        print(\"Next Token: \",next_token)\n",
    "        if result_count is not None and result_count > 0 and next_token is not None:\n",
    "            # print(\"Start Date: \", start_list[i])\n",
    "            append_to_csv(json_response, csv_to_file)\n",
    "            count += result_count\n",
    "            total_followers += result_count\n",
    "            print(\"Total # of followers added: \", total_followers)\n",
    "            print(\"count\",count)\n",
    "            print(\"-------------------\")\n",
    "            time.sleep(5)                \n",
    "    # If no next token exists\n",
    "    else:\n",
    "        if result_count is not None and result_count > 0:\n",
    "            print(\"-------------------\")\n",
    "            # print(\"Start Date: \", start_list[i])\n",
    "            append_to_csv(json_response, csv_to_file)\n",
    "            count += result_count\n",
    "            total_followers += result_count\n",
    "            print(\"Total # of followers added: \", total_followers)\n",
    "            print(\"count\",count)\n",
    "            print(\"-------------------\")\n",
    "            time.sleep(5)\n",
    "        \n",
    "        #Since this is the final request, turn flag to false to move to the next time period.\n",
    "        flag = False\n",
    "        next_token = None\n",
    "    time.sleep(5)\n",
    "print(\"Total number of results: \", total_followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LL2HPJQUASBHAZZZ'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['next_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n",
       " 'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
       " 'next_token': 'LL2HPJQUASBHAZZZ',\n",
       " 'pagination_token': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d731139d9ad7e7749c450c5b8b50ae597506969cf6798becac77e3dbff3ddb16"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('twit_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
